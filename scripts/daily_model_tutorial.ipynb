{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting started with the eemeter library\n",
    "\n",
    "This jupyter notebook is an interactive tutorial. It walks through loading data, running the CalTRACK methods, and plotting results. You'll run all the code yourself. Cells can be executed with `<shift><enter>`. If you feel so inspired, make edits to the code in these cells and dig deeper.\n",
    "\n",
    "### Note on tutorial scope\n",
    "\n",
    "This tutorial assumes the reader has properly installed python and the eemeter package (`pip install eemeter`) and has a basic working knowledge of python syntax and usage.\n",
    "\n",
    "## Outline\n",
    "\n",
    "This tutorial is a self-paced walkthrough of how to use the eemeter package. We'll cover the following:\n",
    "\n",
    "- Background - why this library\n",
    "- Loading data\n",
    "- Plotting and visualization\n",
    "- Filtering data to baseline or reporting periods\n",
    "- Creating design matrix datasets\n",
    "- Fitting baseline (and reporting) models\n",
    "- Using fitted models for prediction\n",
    "- Computing CalTRACK metered savings\n",
    "\n",
    "The tutorial is focused on demonstrating how to use the package to run the CalTRACK Hourly, Daily, and Billing methods on hourly, daily, and billing meter data.\n",
    "\n",
    "## Background and Cautions\n",
    "\n",
    "At time of writing (February 2023), the OpenEEmeter, as implemented in the `eemeter` package, contains the most complete open source implementation of the [CalTRACK methods](http://www.caltrack.org/), which specify a way of calculating avoided energy use at a single meter. However, using the OpenEEmeter to calculate avoided energy use does not in itself guarantee compliance with the CalTRACK method specification. Nor is using the OpenEEmeter a requirement of the CalTRACK methods. The eemeter package is a toolkit that may help with implementing a CalTRACK compliant analysis, as it provides a particular implementation of the CalTRACK methods which consists of a set of functions, parameters, and classes which can be configured to run the CalTRACK methods and variants. Please keep in mind while using the package that the eemeter assumes certain data cleaning tasks that are specified in the CalTRACK methods have occurred *prior* to usage with the eemeter. The package will create warnings to expose errors of this nature where possible.\n",
    "\n",
    "The eemeter package is built for flexibility and modularity. While this is generally helpful and makes it easier to use the package, one potential consequence of this for users is that without being careful to follow the both the eemeter documentation *and* the guidance provided in the CalTRACK methods, it is very possible to use the eemeter in a way that does not comply with the CalTRACK methods. For example, while the CalTRACK methods set specific hard limits for the purpose of standardization and consistency, the eemeter can be configured to edit or entirely ignore those limits. The main reason for this flexibility is that the emeter package is used not only to comply with the CalTRACK methods, but also to develop, test, and propose potential changes to those methods.\n",
    "\n",
    "Rather than providing a single method that directly calculates avoided energy use from the required inputs, the eemeter library provides a series of modular functions that can be strung together in a variety of ways. The tutorial below describes common usage and sequencing of these functions, especially when it might not otherwise be apparent from the [API documentation](https://eemeter.openee.io/api.html).\n",
    "\n",
    "Some new users have assumed that the eemeter package constitutes an entire application suitable for running metering analytics at scale. This is not necessarily the case. It is designed instead to be embedded within other applications or to be used in one-off analyses. The eemeter is a toolbox that leaves to the user decisions about when to use or how to embed the provided tools within other applications. This limitation is an important consequence of the decision to make the methods and implementation as open and accessible as possible.\n",
    "\n",
    "As you dive in, remember that this is a work in progress and that we welcome feedback and contributions. To contribute, please open an [issue](https://github.com/openeemeter/eemeter/issues) or a [pull request](https://github.com/openeemeter/eemeter/pulls) on github.\n",
    "\n",
    "### Jupyter housekeeping\n",
    "\n",
    "*Note: these Jupyter cell magics enable some useful special features but are unrelated to eemeter.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inline plotting\n",
    "%matplotlib inline\n",
    "\n",
    "# allow live package editing\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the eemeter library\n",
    "\n",
    "Once the eemeter has been installed, it can be imported as shown below. The package exposes most of its API at the top level of the library, so this single import is generally sufficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import eemeter as em"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial requires eemeter version > 4.x.x. You can verify the version you have installed with the command below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.0.0a2'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "em.get_version()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data\n",
    "\n",
    "The three essential inputs to eemeter library functions are the following:\n",
    "\n",
    "1. Meter data\n",
    "2. Temperature data from a nearby weather station\n",
    "3. Project or intervention dates\n",
    "\n",
    "Users of the library are responsible for obtaining and formatting this data (to get weather data, see [eeweather](https://eeweather.openee.io/), which helps perform site to weather station matching and can pull and cache temperature data directly from public (US) data sources). Some samples come loaded with the library and we'll load these first to save you the trouble of loading in your own data. The simulated sample data additionally has the useful property that we can load the same underlying data in three different frequencies: hourly, daily, and billing data.\n",
    "\n",
    "We directly use [pandas](https://pandas.pydata.org/) `DataFrame` amd `Series` objects to hold the input meter and temperature time series data, which allows us to easily take advantage of the powerful methods provided by the pandas package. Use pandas has the added advantage that usage is a bit more familiar to pythonistas who work frequently with data of this nature in python. These formats are discussed in more detail below. If working with your own data instead of these samples, please refer directly to the excellent pandas documentation for instructions for loading data (e.g., [pandas.read_csv](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html)). For some common cases, eemeter does come packaged with loading methods, but these will only work for particular data formats.\n",
    "\n",
    "Useful eemeter methods for loading and manipulating data:\n",
    "\n",
    "- [`eemeter.meter_data_from_csv`](http://eemeter.openee.io/api.html#eemeter.meter_data_from_csv): Load meter data from CSV.\n",
    "- [`eemeter.temperature_data_from_csv`](http://eemeter.openee.io/api.html#eemeter.temperature_data_from_csv): Load temperature data from CSV.\n",
    "- [`eemeter.meter_data_from_json`](http://eemeter.openee.io/api.html#eemeter.meter_data_from_json): Load meter data from JSON.\n",
    "- [`eemeter.temperature_data_from_json`](http://eemeter.openee.io/api.html#eemeter.temperature_data_from_json): Load temperature data from JSON.\n",
    "- [`eemeter.samples`](http://eemeter.openee.io/api.html#eemeter.samples): Return a list of sample data names.\n",
    "- [`eemeter.load_sample`](http://eemeter.openee.io/api.html#eemeter.load_sample): Load sample data by name.\n",
    "- [`eemeter.as_freq`](http://eemeter.openee.io/api/html#eemeter.as_freq): Coerce meter data into a different frequency.\n",
    "- `eemeter.trim`: Trim two time series datasets so that they correspond to identical intervals.\n",
    "\n",
    "*Remember: the sample data is simulated, not real!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = em.load_test_data(\"hourly_treatment_data\")\n",
    "\n",
    "df_baseline = df[[\"temperature\", \"observed_baseline\"]]\n",
    "df_baseline = df_baseline.rename(columns={\"observed_baseline\": \"observed\"})\n",
    "\n",
    "df_reporting = df[[\"temperature\", \"observed_reporting\"]]\n",
    "df_reporting = df_reporting.rename(columns={\"observed_reporting\": \"observed\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "MergeError",
     "evalue": "incompatible merge keys [0] datetime64[ns, America/Chicago] and datetime64[ns, UTC], must be the same type",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMergeError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m df_reporting_n \u001b[38;5;241m=\u001b[39m df_reporting\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;28mid\u001b[39m]\n\u001b[1;32m      9\u001b[0m df_reporting_n\u001b[38;5;241m.\u001b[39mindex \u001b[38;5;241m=\u001b[39m df_reporting_n\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mtz_localize(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUTC\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mtz_convert(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAmerica/Chicago\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 11\u001b[0m baseline_data \u001b[38;5;241m=\u001b[39m \u001b[43mem\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDailyBaselineData\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_baseline_n\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_electricity_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# reporting_data = em.DailyReportingData(df_reporting_n, is_electricity_data=True)\u001b[39;00m\n",
      "File \u001b[0;32m/app/applied_data_science/eemeter/eemeter/eemeter/models/daily/data.py:28\u001b[0m, in \u001b[0;36m_DailyData.__init__\u001b[0;34m(self, df, is_electricity_data)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtz \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m#TODO re-examine dq/warning pattern. keep consistent between\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# either implicitly setting as side effects, or returning and assigning outside\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_df, temp_coverage \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m sufficiency_df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_df\u001b[38;5;241m.\u001b[39mmerge(temp_coverage, left_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, right_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mouter\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     31\u001b[0m disqualification, warnings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_data_sufficiency(sufficiency_df)\n",
      "File \u001b[0;32m/app/applied_data_science/eemeter/eemeter/eemeter/models/daily/data.py:212\u001b[0m, in \u001b[0;36m_DailyData._set_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    209\u001b[0m     df\u001b[38;5;241m.\u001b[39mloc[df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mobserved\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mobserved\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mnan\n\u001b[1;32m    211\u001b[0m meter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compute_meter_value_df(df)\n\u001b[0;32m--> 212\u001b[0m temp, temp_coverage \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_compute_temperature_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmeter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    213\u001b[0m final_df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_merge_meter_temp(meter, temp)\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m final_df, temp_coverage\n",
      "File \u001b[0;32m/app/applied_data_science/eemeter/eemeter/eemeter/models/daily/data.py:137\u001b[0m, in \u001b[0;36m_DailyData._compute_temperature_features\u001b[0;34m(self, df, meter_index)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    135\u001b[0m     \u001b[38;5;66;03m#TODO hacky method of avoiding the last index nan convention\u001b[39;00m\n\u001b[1;32m    136\u001b[0m     buffer_idx \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2090-01-01 00:00:00+00:00\u001b[39m\u001b[38;5;124m'\u001b[39m) \n\u001b[0;32m--> 137\u001b[0m     temperature_features \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_temperature_features\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmeter_index\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munion\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mbuffer_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    139\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtemp_series\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata_quality\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    142\u001b[0m     temperature_features \u001b[38;5;241m=\u001b[39m temperature_features[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    143\u001b[0m temp \u001b[38;5;241m=\u001b[39m temperature_features[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtemperature_mean\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mrename(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtemperature\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/app/applied_data_science/eemeter/eemeter/eemeter/features.py:514\u001b[0m, in \u001b[0;36mcompute_temperature_features\u001b[0;34m(meter_data_index, temperature_data, heating_balance_points, cooling_balance_points, data_quality, temperature_mean, degree_day_method, percent_hourly_coverage_per_day, percent_hourly_coverage_per_billing_period, use_mean_daily_values, tolerance, keep_partial_nan_rows)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;66;03m# aggregate temperatures\u001b[39;00m\n\u001b[1;32m    513\u001b[0m temp_df \u001b[38;5;241m=\u001b[39m temperature_data\u001b[38;5;241m.\u001b[39mto_frame(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemp\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 514\u001b[0m temp_groups \u001b[38;5;241m=\u001b[39m \u001b[43m_matching_groups\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmeter_data_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemp_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtolerance\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    515\u001b[0m temp_aggregations \u001b[38;5;241m=\u001b[39m temp_groups\u001b[38;5;241m.\u001b[39magg({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemp\u001b[39m\u001b[38;5;124m\"\u001b[39m: temp_agg_funcs})\n\u001b[1;32m    517\u001b[0m \u001b[38;5;66;03m# expand temp aggregations by faking and deleting the `meter_value` column.\u001b[39;00m\n\u001b[1;32m    518\u001b[0m \u001b[38;5;66;03m# I haven't yet figured out a way to avoid this and get the desired\u001b[39;00m\n\u001b[1;32m    519\u001b[0m \u001b[38;5;66;03m# structure and behavior. (philngo)\u001b[39;00m\n",
      "File \u001b[0;32m/app/applied_data_science/eemeter/eemeter/eemeter/features.py:184\u001b[0m, in \u001b[0;36m_matching_groups\u001b[0;34m(index, df, tolerance)\u001b[0m\n\u001b[1;32m    177\u001b[0m index_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex_col\u001b[39m\u001b[38;5;124m\"\u001b[39m: index}, index\u001b[38;5;241m=\u001b[39mindex)\n\u001b[1;32m    179\u001b[0m \u001b[38;5;66;03m# get a dataframe containing mean temperature\u001b[39;00m\n\u001b[1;32m    180\u001b[0m \u001b[38;5;66;03m#   1) merge by matching temperature to closest previous meter start date,\u001b[39;00m\n\u001b[1;32m    181\u001b[0m \u001b[38;5;66;03m#      up to tolerance limit, using merge_asof.\u001b[39;00m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;66;03m#   2) group by meter_index, and take the mean, ignoring all columns except\u001b[39;00m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;66;03m#      the temperature column.\u001b[39;00m\n\u001b[0;32m--> 184\u001b[0m groups \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmerge_asof\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[43m    \u001b[49m\u001b[43mleft\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mleft_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtolerance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtolerance\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex_col\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m groups\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/pandas/core/reshape/merge.py:688\u001b[0m, in \u001b[0;36mmerge_asof\u001b[0;34m(left, right, on, left_on, right_on, left_index, right_index, by, left_by, right_by, suffixes, tolerance, allow_exact_matches, direction)\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmerge_asof\u001b[39m(\n\u001b[1;32m    438\u001b[0m     left: DataFrame \u001b[38;5;241m|\u001b[39m Series,\n\u001b[1;32m    439\u001b[0m     right: DataFrame \u001b[38;5;241m|\u001b[39m Series,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    451\u001b[0m     direction: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbackward\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    452\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[1;32m    453\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    454\u001b[0m \u001b[38;5;124;03m    Perform a merge by key distance.\u001b[39;00m\n\u001b[1;32m    455\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    686\u001b[0m \u001b[38;5;124;03m    4 2016-05-25 13:30:00.048   AAPL   98.00       100     NaN     NaN\u001b[39;00m\n\u001b[1;32m    687\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 688\u001b[0m     op \u001b[38;5;241m=\u001b[39m \u001b[43m_AsOfMerge\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    689\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    690\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    691\u001b[0m \u001b[43m        \u001b[49m\u001b[43mon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    692\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    693\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mright_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    694\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    695\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mright_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    696\u001b[0m \u001b[43m        \u001b[49m\u001b[43mby\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    697\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_by\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft_by\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    698\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_by\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mright_by\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    699\u001b[0m \u001b[43m        \u001b[49m\u001b[43msuffixes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msuffixes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    700\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43masof\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    701\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtolerance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtolerance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_exact_matches\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_exact_matches\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    703\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdirection\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdirection\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    704\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result()\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/pandas/core/reshape/merge.py:1921\u001b[0m, in \u001b[0;36m_AsOfMerge.__init__\u001b[0;34m(self, left, right, on, left_on, right_on, left_index, right_index, by, left_by, right_by, suffixes, how, tolerance, allow_exact_matches, direction)\u001b[0m\n\u001b[1;32m   1915\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1916\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_exact_matches must be boolean, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1917\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassed \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mallow_exact_matches\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1918\u001b[0m     )\n\u001b[1;32m   1919\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MergeError(msg)\n\u001b[0;32m-> 1921\u001b[0m \u001b[43m_OrderedMerge\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1922\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1923\u001b[0m \u001b[43m    \u001b[49m\u001b[43mleft\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1924\u001b[0m \u001b[43m    \u001b[49m\u001b[43mright\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1925\u001b[0m \u001b[43m    \u001b[49m\u001b[43mon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1926\u001b[0m \u001b[43m    \u001b[49m\u001b[43mleft_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1927\u001b[0m \u001b[43m    \u001b[49m\u001b[43mright_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mright_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1928\u001b[0m \u001b[43m    \u001b[49m\u001b[43mleft_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1929\u001b[0m \u001b[43m    \u001b[49m\u001b[43mright_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mright_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1930\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1931\u001b[0m \u001b[43m    \u001b[49m\u001b[43msuffixes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msuffixes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1932\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfill_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1933\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/pandas/core/reshape/merge.py:1837\u001b[0m, in \u001b[0;36m_OrderedMerge.__init__\u001b[0;34m(self, left, right, on, left_on, right_on, left_index, right_index, suffixes, fill_method, how)\u001b[0m\n\u001b[1;32m   1823\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m   1824\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1825\u001b[0m     left: DataFrame \u001b[38;5;241m|\u001b[39m Series,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1834\u001b[0m     how: JoinHow \u001b[38;5;241m|\u001b[39m Literal[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124masof\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mouter\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1835\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1836\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfill_method \u001b[38;5;241m=\u001b[39m fill_method\n\u001b[0;32m-> 1837\u001b[0m     \u001b[43m_MergeOperation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1838\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1839\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1840\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1841\u001b[0m \u001b[43m        \u001b[49m\u001b[43mon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1842\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1843\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1844\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mright_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1845\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mright_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1846\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1847\u001b[0m \u001b[43m        \u001b[49m\u001b[43msuffixes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msuffixes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1848\u001b[0m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# factorize sorts\u001b[39;49;00m\n\u001b[1;32m   1849\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/pandas/core/reshape/merge.py:799\u001b[0m, in \u001b[0;36m_MergeOperation.__init__\u001b[0;34m(self, left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, indicator, validate)\u001b[0m\n\u001b[1;32m    796\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m right_drop:\n\u001b[1;32m    797\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright\u001b[38;5;241m.\u001b[39m_drop_labels_or_levels(right_drop)\n\u001b[0;32m--> 799\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_require_matching_dtypes\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mleft_join_keys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mright_join_keys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_tolerance(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft_join_keys)\n\u001b[1;32m    802\u001b[0m \u001b[38;5;66;03m# validate the merge keys dtypes. We may need to coerce\u001b[39;00m\n\u001b[1;32m    803\u001b[0m \u001b[38;5;66;03m# to avoid incompatible dtypes\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/pandas/core/reshape/merge.py:2053\u001b[0m, in \u001b[0;36m_AsOfMerge._maybe_require_matching_dtypes\u001b[0;34m(self, left_join_keys, right_join_keys)\u001b[0m\n\u001b[1;32m   2050\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2051\u001b[0m     rt \u001b[38;5;241m=\u001b[39m right_join_keys[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m-> 2053\u001b[0m \u001b[43m_check_dtype_match\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/pandas/core/reshape/merge.py:2037\u001b[0m, in \u001b[0;36m_AsOfMerge._maybe_require_matching_dtypes.<locals>._check_dtype_match\u001b[0;34m(left, right, i)\u001b[0m\n\u001b[1;32m   2032\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2033\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   2034\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mincompatible merge keys [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(left\u001b[38;5;241m.\u001b[39mdtype)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2035\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(right\u001b[38;5;241m.\u001b[39mdtype)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, must be the same type\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2036\u001b[0m     )\n\u001b[0;32m-> 2037\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m MergeError(msg)\n",
      "\u001b[0;31mMergeError\u001b[0m: incompatible merge keys [0] datetime64[ns, America/Chicago] and datetime64[ns, UTC], must be the same type"
     ]
    }
   ],
   "source": [
    "n = 0\n",
    "\n",
    "id = df_baseline.index.get_level_values(0).unique()[n]\n",
    "\n",
    "df_baseline_n = df_baseline.loc[id]\n",
    "df_baseline_n.index = df_baseline_n.index.tz_localize('UTC').tz_convert('America/Chicago')\n",
    "\n",
    "df_reporting_n = df_reporting.loc[id]\n",
    "df_reporting_n.index = df_reporting_n.index.tz_localize('UTC').tz_convert('America/Chicago')\n",
    "\n",
    "baseline_data = em.DailyBaselineData(df_baseline_n, is_electricity_data=True)\n",
    "# reporting_data = em.DailyReportingData(df_reporting_n, is_electricity_data=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More about the meter data data structure\n",
    "\n",
    "The convention for formatting meter data is to create a [pandas DataFrame](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html) with a [DatetimeIndex](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DatetimeIndex.html) called `start` and a single column of meter readings called `value`. The index datetime values represent the start dates of each metering period. The end of each period is the start of the next period, even for data with variable period lengths like billing data. The end date of the last period can be supplied by appending an extra period with the final end date and a NaN value. Missing data is represented by one or more periods of value NaN. Data should be sorted by time and deduplicated prior to use with eemeter. Timestamps must be timezone aware.\n",
    "\n",
    "Data is formatted like this as a convenience to avoid the need to store a start and an end period for each data point. However, the convention that uses start dates as timestamps can be a bit confusing. Make sure that if you are starting with billing data, which is sometimes defined primarily by period end dates that the transformation is done properly so that the meter data ends up with start dates as time stamps.\n",
    "\n",
    "Take a look at the hourly, daily, and billing data we just loaded. It follows the conventions described above. Notice that the format is identical but the timestamps and values are different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meter_data_hourly.head()  # pandas.DataFrame.head filters to just the first 5 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meter_data_daily.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meter_data_billing.tail()  # last 5 rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The convention for formatting temperature is as a [pandas Series](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.html), also with a [DatetimeIndex](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DatetimeIndex.html). These three versions are all exactly the same. That is because we *always* start with hourly temperature data. This is necessary even for daily and billing analyses because we must be able to aggregate the temperatures in different ways over different time series - including dates in many different timezones, which have midnight timestamps which don't always align with the UTC midnights provided in preaggregated daily data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temperature_data_hourly.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temperature_data_daily.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temperature_data_billing.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formatting meter and temperature data\n",
    "\n",
    "If you are unsure whether your meter and/or temperature data are formatted correctly, you can use eemeter to check.\n",
    "\n",
    "Formatting meter data:\n",
    "- eemeter.format_energy_data_for_caltrack\n",
    "\n",
    "This will ensure that:\n",
    "- any columns named 'start', 'Start', 'Datetime', 'datetime', 'timestamp', or 'Timestamp' are set as the index.\n",
    "- the index is of pandas.DateTimeIndex format, localised to the specified timezone and arranged in ascending order.\n",
    "- the data is in pandas.DataFrame format.\n",
    "- the index is named 'start' and the energy consumption column is named 'value'.\n",
    "- the data is resampled to an appropriate frequency.\n",
    "\n",
    "Note for this you will be required to specify which eemeter model you wish to format for.\n",
    "\n",
    "Assuming a meter dataset has come in the wrong format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#flipping df\n",
    "df = meter_data_hourly.reindex(index=meter_data_hourly.index[::-1])\n",
    "\n",
    "#inserting new value of 0.04 at 09.34 22/11/2015\n",
    "new_start = pd.to_datetime(\"22/11/2015 09:34\").tz_localize('UTC')\n",
    "df.loc[new_start] = [0.04]\n",
    "\n",
    "#rename column name to 'consumption'\n",
    "df.rename(columns={'value':'consumption'}, inplace=True)\n",
    "\n",
    "#df_flipped to pd.Series\n",
    "meter_data_hourly_incorrect_format = df.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "meter_data_hourly_incorrect_format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use eemeter.format_energy_data_for_caltrack to correct this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meter_data_hourly_reformatted = eemeter.format_energy_data_for_caltrack(meter_data_hourly_incorrect_format, method='hourly')\n",
    "meter_data_hourly_reformatted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This can then be tailored to both eemeter daily and eemeter billing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meter_data_daily_reformatted = eemeter.format_energy_data_for_caltrack(meter_data_hourly_incorrect_format, method='daily')\n",
    "meter_data_daily_reformatted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meter_data_billing_reformatted = eemeter.format_energy_data_for_caltrack(meter_data_hourly_incorrect_format, method='billing')\n",
    "meter_data_billing_reformatted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, we can use eemeter.format_temperature_data_for_caltrack to format temperature data correctly:\n",
    "- eemeter.format_temperature_data_for_caltrack\n",
    "\n",
    "This will ensure that:\n",
    "- any columns named 'start', 'Start', 'Datetime', 'datetime', 'timestamp', or 'Timestamp' are set as the index.\n",
    "- the index is of pandas.DateTimeIndex format, localised to the specified timezone and arranged in ascending order.\n",
    "- the data is in pandas.Series format.\n",
    "- the data is of hourly frequency, capturing the temperature on the hour, if input temperature data is of greater than hourly frequency.\n",
    "\n",
    "Note that input data must be of a minimum hourly frequency for this function to operate.\n",
    "\n",
    "Assuming data has come in the wrong format, as a DataFrame in descending order with random sub-hourly values included:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "# temperature_data to pd.DateFrame\n",
    "temperature_data_incorrectly_formatted = pd.DataFrame(temperature_data_hourly)\n",
    "\n",
    "# inserting new value of 0.04 at 09.34 22/11/2015\n",
    "new_start = pd.to_datetime(\"22/11/2015 06:34\").tz_localize('UTC')\n",
    "temperature_data_incorrectly_formatted.loc[new_start] = [0.04]\n",
    "\n",
    "# flipping df\n",
    "temperature_data_incorrectly_formatted = temperature_data_incorrectly_formatted.sort_index()\n",
    "temperature_data_incorrectly_formatted = temperature_data_incorrectly_formatted.reindex(index=temperature_data_incorrectly_formatted.index[::-1])\n",
    "\n",
    "# rename column name to 'consumption'\n",
    "temperature_data_incorrectly_formatted.rename(columns={'value': 'consumption'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temperature_data_incorrectly_formatted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use eemeter.format_temperature_data_for_caltrack to correct this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temperature_data_reformatted = eemeter.format_temperature_data_for_caltrack(temperature_data_incorrectly_formatted)\n",
    "temperature_data_reformatted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trimming datasets\n",
    "\n",
    "It is possible to ensure that two or more time series datasets (most likely two gas and electricity datasets) correspond to identical intervals for use with eemeter. eemeter.trim enables you to easily format datasets for this purpose. The following example trims two electricity datasets of differing  intervals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "electricity_data_1, temperature_data_1, metadata_1 = eemeter.load_sample('uk-electricity-hdd-only-hourly-sample-1', tempF=False)\n",
    "electricity_data_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "electricity_data_2, temperature_data_2, metadata_2 = eemeter.load_sample('uk-electricity-hdd-only-hourly-sample-2', tempF=False)\n",
    "electricity_data_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "electricity_data_1_trimmed, electricity_data_2_trimmed = eemeter.trim(electricity_data_1, electricity_data_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "electricity_data_1_trimmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "electricity_data_2_trimmed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting (part 1)\n",
    "\n",
    "The eemeter plotting functions allow visual exploration of meter and temperature data.\n",
    "\n",
    "### Time series plots\n",
    "\n",
    "Plotting in time series, we see the difference in the frequency of the data more clearly.\n",
    "\n",
    "- [`eemeter.plot_time_series`](http://eemeter.openee.io/api/html#eemeter.plot_time_series): Plot meter and temperature data in time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eemeter.plot_time_series(meter_data_hourly, temperature_data_hourly, figsize=(16, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eemeter.plot_time_series(meter_data_daily, temperature_data_daily, figsize=(16, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eemeter.plot_time_series(meter_data_billing, temperature_data_billing, figsize=(16, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Energy signature plots\n",
    "\n",
    "The following stacks the three versions of the data - hourly, billing and daily - right on top of each other in energy signature form. This shows the temperature dependence of usage on external temperatures. These plots convert the meter data to \"usage per day\", which normalizes things and makes usage patterns appear roughly comparable at different sampling intervals.\n",
    "\n",
    "- [`eemeter.plot_energy_signature`](http://eemeter.openee.io/api/html#eemeter.plot_energy_signature): Plot meter and temperature data as an energy signature.\n",
    "\n",
    "*Remember, this data is simulated. If these correlations look too good to be true, they are!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = eemeter.plot_energy_signature(meter_data_hourly, temperature_data_hourly, figsize=(14, 8))\n",
    "eemeter.plot_energy_signature(meter_data_daily, temperature_data_daily, ax=ax)\n",
    "eemeter.plot_energy_signature(meter_data_billing, temperature_data_billing, ax=ax)\n",
    "ax.legend(labels=['hourly', 'daily', 'billing'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering to a baseline data\n",
    "\n",
    "The CalTRACK methods require building a model of the usage during the baseline period and then projecting that forward into the reporting period. Before we can build the baseline model we need to get isolate 365 days of meter data as immediately prior to the end of the baseline period as we can. The following function performs this filtering for us an returns a new dataset with only baseline data.\n",
    "\n",
    "- [`eemeter.get_baseline_data`](http://eemeter.openee.io/api/html#eemeter.get_baseline_data): Filter a dataset to baseline period data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dateutil.relativedelta import relativedelta\n",
    "baseline_meter_data_hourly, baseline_warnings_hourly = eemeter.get_baseline_data(\n",
    "    meter_data_hourly, start=baseline_end_date - relativedelta(years=1),\n",
    "        end=baseline_end_date,\n",
    "        max_days=None,\n",
    "    )\n",
    "\n",
    "baseline_meter_data_daily, baseline_warnings_daily = eemeter.get_baseline_data(\n",
    "    meter_data_daily, start=baseline_end_date - relativedelta(years=1),\n",
    "        end=baseline_end_date,\n",
    "        max_days=None,\n",
    ")\n",
    "\n",
    "baseline_meter_data_billing, baseline_warnings_billing = eemeter.get_baseline_data(\n",
    "    meter_data_billing, start=baseline_end_date - relativedelta(years=1),\n",
    "        end=baseline_end_date,\n",
    "        max_days=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To give you a sense for what this data looks like, let's tail the data again. Remember that we had a baseline end date of 2016-12-26 - so this data goes up to that data but no further, as we specified above with the `end` argument. It's also no more than 365 days long, as we specified above with the `max_days` argument. Notice that the billing data is a bit shorter because of the unevenness of billing periods. Billing periods that fall across (rather than exactly at) the boundaries are removed in this method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_meter_data_hourly.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_meter_data_daily.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_meter_data_billing.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If there had been any issues (e.g., unexpected gaps in the data) in filtering the data to the baseline period, some warnings would have been reported. This time we got off easy, but that will not always be the case in real-life datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_warnings_hourly, baseline_warnings_daily, baseline_warnings_billing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean CalTRACK Daily/Billing meter data\n",
    "\n",
    "CalTRACK defines certain changes to the meter data such as:\n",
    "\n",
    "- CalTRACK 2.2.3.4: Off-cycle reads (spanning less than 25 days) should be dropped from analysis\n",
    "- CalTRACK 2.2.3.5: For pseudo-monthly billing cycles, periods spanning more than 35 days should be dropped from analysis. For bi-monthly billing cycles, periods spanning more than 70 days should be dropped from the analysis.\n",
    "- CalTRACK 2.2.2.1: If summing to daily usage from higher frequency interval data, no more than 50% of high-frequency values should be missing. Missing values should be filled in with average of non-missing values (e.g., for hourly data, 24 * average hourly usage).\n",
    "\n",
    "A helper function was created to handle these cases called `clean_caltrack_billing_daily_data`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_meter_data_billing = eemeter.clean_caltrack_billing_daily_data(baseline_meter_data_billing, 'billing')\n",
    "\n",
    "baseline_meter_data_daily = eemeter.clean_caltrack_billing_daily_data(baseline_meter_data_daily, 'daily')\n",
    "\n",
    "baseline_meter_data_daily_from_hourly = eemeter.clean_caltrack_billing_daily_data(baseline_meter_data_hourly, 'hourly')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating CalTRACK Daily/Billing Method datasets\n",
    "\n",
    "The CalTRACK daily and billing methods specify a way of modeling the energy signature we plotted a few cells above. We need to select a model which fits the data as well as possible. The parameters in the model are heating and cooling balance points (i.e., the temperatures at which heating/cooling related energy use tend to kick in), and the heating and cooling beta parameters, which define the slope of the energy response to incremental differences between outdoor temperature and the balance point. We'll do a grid search over possible heating and cooling balance points and fit models to the [heating and cooling degree days](https://en.wikipedia.org/wiki/Heating_degree_day)) defined by the outdoor temperatures and each of those balance points. To do this, we precompute the heating and cooling degree days using the methods below before we feed them into the modeling routines.\n",
    "\n",
    "To make this dataset, we need to merge the meter data and temperature data into a single DataFrame. The `compute_usage_per_day_feature` function transforms the meter data into usage per day. The `compute_temperature_features` function lets us create a bunch of heating and cooling degree day values if we specify balance points to use. In this case, we'll use the wide balance point ranges recommended in the CalTRACK spec. Then we can combine the two using `merge_features`.\n",
    "\n",
    "- [`eemeter.create_caltrack_daily_design_matrix`](http://eemeter.openee.io/api/html#eemeter.create_caltrack_daily_design_matrix): Create a design matrix for CalTRACK daily methods.\n",
    "- [`eemeter.create_caltrack_billing_design_matrix`](http://eemeter.openee.io/api/html#eemeter.create_caltrack_billing_design_matrix): Create a design matrix for CalTRACK billing methods.\n",
    "- [`eemeter.compute_usage_per_day_feature`](http://eemeter.openee.io/api/html#eemeter.compute_usage_per_day_feature): Transform meter data into usage per day.\n",
    "- [`eemeter.compute_temperature_features`](http://eemeter.openee.io/api/html#eemeter.compute_temperature_features): Compute heating and cooling degree days and other useful temperature features.\n",
    "- [`eemeter.merge_features`](http://eemeter.openee.io/api/html#eemeter.merge_features): Combine a list of Dataframe or Series objects which share an index into a single DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "design_matrix_daily = eemeter.create_caltrack_daily_design_matrix(\n",
    "    baseline_meter_data_daily, temperature_data_daily,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A preview of this dataset is shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "design_matrix_daily.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "design_matrix_daily.index.min(), design_matrix_daily.index.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do roughly the same thing for the billing data, adding a tolerance as specified in the CalTRACK methods. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "design_matrix_billing = eemeter.create_caltrack_billing_design_matrix(\n",
    "    baseline_meter_data_billing, temperature_data_billing,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll notice that this billing data shares the structure used above for the daily data. Notice however that the magnitide of the meter value column is significantly smaller than it was before calling `compute_usage_per_day_feature` - that is because the values are returned as average usage per day, as specified by the CalTRACK methods, not as totals per period, as they are represented in the inputs. The heating/cooling degree days returned by `compute_temperature_features` are also average heating/cooling degree days per day, and not total heating/cooling degree days per period. This averaging behavior can be modified with the `use_mean_daily_values` parameter, which is set to `True` by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "design_matrix_billing.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "design_matrix_billing.index.min(), design_matrix_billing.index.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are not running the CalTRACK hourly methods, at this point you should skip down the the section called \"Running the CalTRACK Billing/Daily Methods\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating CalTRACK Hourly Method datasets\n",
    "\n",
    "The hourly methods require a multi-stage dataset creation process which is a bit more involved than the daily/billing dataset creation process above. There are two primary reasons for this extra complexity. First, unlike the daily/billing methods, the hourly methods build separate models for each calendar month, which adds a few extra steps. Second, also unlike the billing and daily methods, there are two features of the dataset creation which must themselves be fitted to a preliminary dataset -- the occupancy feature and the temperature bin features.\n",
    "\n",
    "### Creating a preliminary dataset\n",
    "\n",
    "The preliminary dataset has some simple time and temperature features. These features do not vary by segment and are precursors to other features (See below for a better explanation of segmentation). This step looks a lot like the daily/billing dataset creation. These features are used subsequently to fit the occupancy and temperature bin features.\n",
    "\n",
    "- [`eemeter.create_caltrack_hourly_preliminary_design_matrix`](http://eemeter.openee.io/api/html#eemeter.create_caltrack_hourly_preliminary_design_matrix): Create a design matrix for the first stage of CalTRACK hourly.\n",
    "- [`eemeter.compute_time_features`](http://eemeter.openee.io/api/html#eemeter.compute_time_features): Create a time feature for the index (`time_of_week`).\n",
    "- [`eemeter.compute_temperature_features`](http://eemeter.openee.io/api/html#eemeter.compute_temperature_features): Compute heating and cooling degree days and other useful temperature features.\n",
    "- [`eemeter.merge_features`](http://eemeter.openee.io/api/html#eemeter.merge_features): Combine a list of Dataframe or Series objects which share an index into a single DataFrame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preliminary_design_matrix_hourly = eemeter.create_caltrack_hourly_preliminary_design_matrix(\n",
    "    baseline_meter_data_hourly, temperature_data_hourly,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a peek at this data. This time, we have only two fixed heating and cooling degree day columns - these are used to fit the occupancy model. But we also have an hour of week column, which is a categorical variable indicating the hour of the week using an integer from 1 to 168 (i.e., `7*24`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preliminary_design_matrix_hourly.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segmentation\n",
    "\n",
    "To handle creating multiple independent models on a shared dataset (as is required for CalTRACK hourly), we have introduced a concept which we are calling segmentation. Segmentation breaks a dataset into $n$ named and weighted subsets.\n",
    "\n",
    "Before we can move on to the next steps of creating the CalTRACK hourly dataset, we need to create a segmentation for the hourly data. We will use this to create 12 independent hourly models - one for each month of the calendar year. The eemeter function for creating these weights is called `segment_time_series` and it takes a `DatetimeIndex` as input.\n",
    "\n",
    "This segmentation matrix contains 1 column for each segment (12 in all), each of which contains the segmentation weights for that column. The segmentation scheme we use here is to have one segment for each month which contains a single fully weighted calendar month and two half-weighted neighboring calendar months. The eemeter code name for this segmentation scheme is called `'three_month_weighted'` (There's also `all`, `one_month`, and `three_month`, each of which behaves a bit differently).\n",
    "\n",
    "We are creating this segmentation over the time index of the baseline period that is represented in the preliminary hourly design matrix.\n",
    "\n",
    "- [`eemeter.segment_time_series`](http://eemeter.openee.io/api/html#eemeter.segment_time_series): Create a segmentation using the specified scheme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segmentation_hourly = eemeter.segment_time_series(\n",
    "    preliminary_design_matrix_hourly.index,\n",
    "    'three_month_weighted'\n",
    ")\n",
    "segmentation_hourly.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These segments are probably a bit easier to understand when plotted visually. The areas in the following chart represent the weights assigned to the data at particular hours. A weight of 1 is full weight, as weight of 0 indicates that the data is ignored for that segment. These segments look like 3-month long tetris blocks and indicate half-weight/full-weight/half-weight for the three months they cover. For instance, the `dec-jan-feb-weighted` segment (which will eventually be used to estimate usage for january) includes a fully weighted january but also half-weighted december and february. These weights wrap around the calendar year, so both January and December of 2017 might end up in the same dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example segmentation weights\n",
    "segmentation_hourly[[\n",
    "    'dec-jan-feb-weighted',\n",
    "    'apr-may-jun-weighted',\n",
    "    'jun-jul-aug-weighted'\n",
    "]].plot.area(stacked=False, alpha=0.3, figsize=(15, 2.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting segmented occupancy lookups\n",
    "\n",
    "Occupancy is estimated by building a simple model from the preliminary design matrix hdd_50 and cdd_65 columns. This is done for each segment independently, so results are returned as a dataframe with one segment of results per column. The `segmentation` argument indicates that the analysis should be done once per segment. Occupancy is determined by hour of week category. A value of 1 for a particular hour indicates an \"occupied\" mode, and a value of 0 indicates \"unoccupied\" mode. These modes are determined by the tendency of the hdd_50/cdd_65 model to over- or under-predict usage for that hour, given a particular threshold between 0 and 1 (if the percent of underpredictions (by count) is lower than that threshold, then the mode is \"unoccupied\", otherwise the mode is \"occupied\").\n",
    "\n",
    "- [`eemeter.estimate_hour_of_week_occupancy`](http://eemeter.openee.io/api/html#eemeter.estimate_hour_of_week_occupancy): Estimate occupancy by time of week for each segment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "occupancy_lookup_hourly = eemeter.estimate_hour_of_week_occupancy(\n",
    "    preliminary_design_matrix_hourly,\n",
    "    segmentation=segmentation_hourly,\n",
    "    # threshold=0.65  # default\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The occupancy lookup is organized by hour of week (rows) and model segment (columns)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "occupancy_lookup_hourly.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting segmented temperature bins\n",
    "\n",
    "Temperature bins are fit for each segment such that each bin has sufficient number of temperature readings.  Separate bins are selected for the occupied and unoccupied cases, based on the temperature values that occurred during each of those cases. Bins are defined by starting with a proposed set of bins (see the `default_bins` argument) and systematically dropping bin endpoints. Bins themselves are not dropped but are effectively combined with neighboring bins. Except for the fact that zero-weighted times are dropped, segment weights are not considered when fitting temperature bins.\n",
    "\n",
    "- [`eemeter.fit_temperature_bins`](http://eemeter.openee.io/api/html#eemeter.fit_temperature_bins): Fit temperature bins to data, dropping bin endpoints for bins that do not meet the minimum temperature count such that remaining bins meet the minimum count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temperature_bins_hourly_occupied, temperature_bins_hourly_unoccupied  = eemeter.fit_temperature_bins(\n",
    "    preliminary_design_matrix_hourly,\n",
    "    segmentation=segmentation_hourly,\n",
    "    occupancy_lookup=occupancy_lookup_hourly,\n",
    "    # default_bins=[30, 45, 55, 65, 75, 90],  # default\n",
    "    # min_temperature_count=20  # default\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because bin fitting and validation is done independently for each segment, results are returned as a dataframe with one segment of results per column. The contents of the dataframe are boolean indicators of whether the bin endpoint should be used for temperatures in that segment. Some bin endpoints are dropped because of insufficient reading counts. The bin endpoints that are dropped for each segment are given a value of `False`. You'll notice in this dataset that the the winter months tend to have combined high temperature bins and the summer months tend to have combined low temperature bins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temperature_bins_hourly_occupied"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With these in hand, now we can combine them into a segmented dataset using the helper function `iterate_segmented_dataset` and a prefabricated feature processor `caltrack_hourly_fit_feature_processor` which is provided to assist creating the segmented dataset given a preliminary design matrix of the form created above. The feature processor transforms the each segment of the dataset using the occupancy lookup and temperature bins created above. We are creating a python `dict` of pandas `Dataframes` - one for each time series segment encountered in the baseline data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segmented_design_matrices_hourly = eemeter.create_caltrack_hourly_segmented_design_matrices(\n",
    "    preliminary_design_matrix_hourly,\n",
    "    segmentation_hourly,\n",
    "    occupancy_lookup_hourly,\n",
    "    temperature_bins_hourly_occupied,\n",
    "    temperature_bins_hourly_unoccupied,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The keys of the dict are segment names. The values are DataFrame objects containing the exact data needed to fit the a CalTRACK hourly model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(segmented_design_matrices_hourly.keys())\n",
    "segmented_design_matrices_hourly['dec-jan-feb-weighted'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the CalTRACK Billing/Daily Methods\n",
    "\n",
    "The following use the design matrix datasets that we created in the previous steps and uses them with the CalTRACK method. This gives us a baseline model, which is the key predictive component of the metered savings calculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_model_results_daily = eemeter.fit_caltrack_usage_per_day_model(\n",
    "    design_matrix_daily,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_model_results_billing = eemeter.fit_caltrack_usage_per_day_model(\n",
    "    design_matrix_billing,\n",
    "    use_billing_presets=True,\n",
    "    weights_col='n_days_kept',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the CalTRACK Hourly Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_segmented_model_hourly = eemeter.fit_caltrack_hourly_model(\n",
    "    segmented_design_matrices_hourly,\n",
    "    occupancy_lookup_hourly,\n",
    "    temperature_bins_hourly_occupied,\n",
    "    temperature_bins_hourly_unoccupied,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting (part 2)\n",
    "\n",
    "### Daily and billing method plots\n",
    "\n",
    "To see what this model fit looks like, we can plot the result against the energy signature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = eemeter.plot_energy_signature(meter_data_daily, temperature_data_daily)\n",
    "baseline_model_results_daily.plot(ax=ax, temp_range=(-5, 88))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = eemeter.plot_energy_signature(meter_data_billing, temperature_data_billing)\n",
    "baseline_model_results_billing.plot(ax=ax, temp_range=(18, 80))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also compare the two models and see that there is a slight, but not drastic, difference between them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = baseline_model_results_daily.model.plot(color='C0', best=True, label='daily')\n",
    "ax = baseline_model_results_billing.model.plot(ax=ax, color='C1', best=True, label='billing')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reporting period metered savings\n",
    "\n",
    "The moment of truth. Calculating CalTRACK metered savings.\n",
    "\n",
    "First, we need a reporting period. The following gets the reporting period date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reporting_start_date = metadata_billing['blackout_start_date']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we get the first year of data for that period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reporting_meter_data_hourly, warnings = eemeter.get_reporting_data(\n",
    "    meter_data_hourly, start=reporting_start_date, max_days=365)\n",
    "\n",
    "reporting_meter_data_daily, warnings = eemeter.get_reporting_data(\n",
    "    meter_data_daily, start=reporting_start_date, max_days=365)\n",
    "\n",
    "reporting_meter_data_billing, warnings = eemeter.get_reporting_data(\n",
    "    meter_data_billing, start=reporting_start_date, max_days=365)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `eemeter.metered_savings` method performs the logic of estimating counterfactual baseline reporting period usage. For this, it requires the fitted baseline model, the reporting period meter data (for its index - so that it can be properly joined later), and corresponding temperature data. Note that this method can return results disaggregated into base load, cooling load, or heating load or as the aggregated usage. We do both here for demonstration purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metered_savings_hourly, error_bands = eemeter.metered_savings(\n",
    "    baseline_segmented_model_hourly, reporting_meter_data_hourly,\n",
    "    temperature_data_hourly\n",
    ")\n",
    "\n",
    "metered_savings_daily, error_bands = eemeter.metered_savings(\n",
    "    baseline_model_results_daily, reporting_meter_data_daily,\n",
    "    temperature_data_daily, with_disaggregated=True\n",
    ")\n",
    "\n",
    "metered_savings_billing, error_bands = eemeter.metered_savings(\n",
    "    baseline_model_results_billing, reporting_meter_data_billing,\n",
    "    temperature_data_billing, with_disaggregated=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metered_savings_hourly.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metered_savings_daily.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metered_savings_billing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"reporting_observed\", \"counterfactual_usage\", \"metered_savings\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metered_savings_hourly[columns].resample('MS').sum().plot(figsize=(10, 6), drawstyle=\"steps-post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metered_savings_daily[columns].resample('MS').sum().plot(figsize=(10, 6), drawstyle=\"steps-post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metered_savings_billing[columns].plot(figsize=(10, 6), drawstyle=\"steps-post\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These can be easily aggregated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_savings_hourly = metered_savings_hourly.metered_savings.sum()\n",
    "percent_savings_hourly = total_savings_hourly / metered_savings_hourly.counterfactual_usage.sum() * 100\n",
    "print('Hourly: Saved {:.1f} kWh in first year ({:.1f}%)'.format(total_savings_hourly, percent_savings_hourly))\n",
    "\n",
    "total_savings_daily = metered_savings_daily.metered_savings.sum()\n",
    "percent_savings_daily = total_savings_daily / metered_savings_daily.counterfactual_usage.sum() * 100\n",
    "print('Daily: Saved {:.1f} kWh in first year ({:.1f}%)'.format(total_savings_daily, percent_savings_daily))\n",
    "\n",
    "total_savings_billing = metered_savings_billing.metered_savings.sum()\n",
    "percent_savings_billing = total_savings_billing / metered_savings_billing.counterfactual_usage.sum() * 100\n",
    "print('Billing: Saved {:.1f} kWh in first year ({:.1f}%)'.format(total_savings_billing, percent_savings_billing))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE**: These results differ somewhat due to the different lengths of the reporting periods - the billing version of the reporting period was a bit shorter because the billing periods over which we computed savings didn't exactly align with 365 day period we requested, as they did for the daily reporting period data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annual weather-normalized modeled savings\n",
    "\n",
    "If we want to compute annual weather normalized modeled savings, we'll need a reporting period model. The following code repeats what we did for the baseline period with the reporting period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reporting_preliminary_design_matrix_hourly = eemeter.create_caltrack_hourly_preliminary_design_matrix(\n",
    "    reporting_meter_data_hourly, temperature_data_hourly,\n",
    ")\n",
    "reporting_segmentation_hourly = eemeter.segment_time_series(\n",
    "    reporting_preliminary_design_matrix_hourly.index,\n",
    "    'three_month_weighted'\n",
    ")\n",
    "reporting_occupancy_lookup_hourly = eemeter.estimate_hour_of_week_occupancy(\n",
    "    reporting_preliminary_design_matrix_hourly,\n",
    "    segmentation=reporting_segmentation_hourly,\n",
    ")\n",
    "reporting_temperature_bins_hourly_occupied, reporting_temperature_bins_hourly_unoccupied = eemeter.fit_temperature_bins(\n",
    "    reporting_preliminary_design_matrix_hourly,\n",
    "    segmentation=reporting_segmentation_hourly,\n",
    "    occupancy_lookup=reporting_occupancy_lookup_hourly\n",
    ")\n",
    "reporting_segmentation_design_matrices_hourly = eemeter.create_caltrack_hourly_segmented_design_matrices(\n",
    "    reporting_preliminary_design_matrix_hourly,\n",
    "    reporting_segmentation_hourly,\n",
    "    reporting_occupancy_lookup_hourly,\n",
    "    reporting_temperature_bins_hourly_occupied,\n",
    "    reporting_temperature_bins_hourly_unoccupied,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reporting_design_matrix_daily = eemeter.create_caltrack_daily_design_matrix(\n",
    "    reporting_meter_data_daily, temperature_data_daily,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reporting_design_matrix_billing = eemeter.create_caltrack_billing_design_matrix(\n",
    "    reporting_meter_data_billing, temperature_data_billing,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reporting_segmented_model_hourly = eemeter.fit_caltrack_hourly_model(\n",
    "    reporting_segmentation_design_matrices_hourly,\n",
    "    reporting_occupancy_lookup_hourly,\n",
    "    reporting_temperature_bins_hourly_occupied,\n",
    "    reporting_temperature_bins_hourly_unoccupied,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reporting_model_results_daily = eemeter.fit_caltrack_usage_per_day_model(\n",
    "    reporting_design_matrix_daily,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reporting_model_results_billing = eemeter.fit_caltrack_usage_per_day_model(\n",
    "    reporting_design_matrix_billing,\n",
    "    use_billing_presets=True,\n",
    "    weights_col='n_days_kept',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = eemeter.plot_energy_signature(meter_data_daily, temperature_data_daily)\n",
    "ax = baseline_model_results_daily.model.plot(ax=ax, color='C1', best=True, label='baseline', temp_range=(-5, 88))\n",
    "ax = reporting_model_results_daily.model.plot(ax=ax, color='C2', best=True, label='reporting', temp_range=(-5, 88))\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = eemeter.plot_energy_signature(meter_data_billing, temperature_data_billing)\n",
    "ax = baseline_model_results_billing.model.plot(ax=ax, color='C1', best=True, label='baseline', temp_range=(18, 80))\n",
    "ax = reporting_model_results_billing.model.plot(ax=ax, color='C2', best=True, label='reporting', temp_range=(18, 80))\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last thing we need to do before obtaining annualized and weather-normalized results is to obtain normal year temperature data. For simplicity, let's just call 2017 our \"normal year\". To be completely clear, this is not something you would do in practice, but this demonstrates the functionality. To use real temperature normals, check out the [EEWeather](http://eeweather.openee.io/) package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "normal_year_temperatures = temperature_data_daily[temperature_data_daily.index.year == 2017]\n",
    "result_index = pd.date_range('2017-01-01', periods=365, freq='D', tz='UTC')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to obtain our annualized savings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annualized_savings_hourly, annualized_savings_warnings_hourly = eemeter.modeled_savings(\n",
    "    baseline_segmented_model_hourly, reporting_segmented_model_hourly,\n",
    "    result_index, normal_year_temperatures, with_disaggregated=True\n",
    ")\n",
    "\n",
    "annualized_savings_daily, annualized_savings_warnings_daily = eemeter.modeled_savings(\n",
    "    baseline_model_results_daily, reporting_model_results_daily,\n",
    "    result_index, normal_year_temperatures, with_disaggregated=True\n",
    ")\n",
    "\n",
    "annualized_savings_billing, annualized_savings_warnings_billing = eemeter.modeled_savings(\n",
    "    baseline_model_results_billing, reporting_model_results_billing,\n",
    "    result_index, normal_year_temperatures, with_disaggregated=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annualized_savings_hourly.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annualized_savings_daily.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annualized_savings_billing.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following plot demonstrates that in this case, the billing model represents most of the modeled savings as base load savings. This reflects the behavior seen in the model comparison above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, axes = plt.subplots(1, 1, figsize=(10, 4))\n",
    "\n",
    "annualized_savings_hourly[[\n",
    "    'modeled_baseline_usage',\n",
    "    'modeled_reporting_usage',\n",
    "    'modeled_savings',\n",
    "]].plot(ax=axes)\n",
    "axes.set_title('Total normalized/annualized savings')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, axes = plt.subplots(4, 1, figsize=(10, 16))\n",
    "\n",
    "annualized_savings_daily[[\n",
    "    'modeled_baseline_usage',\n",
    "    'modeled_reporting_usage',\n",
    "    'modeled_savings',\n",
    "]].plot(ax=axes[0])\n",
    "axes[0].set_title('Total normalized/annualized savings')\n",
    "\n",
    "annualized_savings_daily[[\n",
    "    'modeled_baseline_cooling_load',\n",
    "    'modeled_reporting_cooling_load',\n",
    "    'modeled_cooling_load_savings',\n",
    "]].plot(ax=axes[1])\n",
    "axes[1].set_title('Modeled cooling load savings')\n",
    "\n",
    "annualized_savings_daily[[\n",
    "    'modeled_baseline_heating_load',\n",
    "    'modeled_reporting_heating_load',\n",
    "    'modeled_heating_load_savings',\n",
    "]].plot(ax=axes[2])\n",
    "axes[2].set_title('Modeled heating load savings')\n",
    "\n",
    "ax = annualized_savings_daily[[\n",
    "    'modeled_baseline_base_load',\n",
    "    'modeled_reporting_base_load',\n",
    "    'modeled_base_load_savings',\n",
    "]].plot(ax=axes[3])\n",
    "axes[3].set_title('Modeled base load savings')\n",
    "lim = axes[3].set_ylim((0, None))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, axes = plt.subplots(4, 1, figsize=(10, 16))\n",
    "\n",
    "annualized_savings_billing[[\n",
    "    'modeled_baseline_usage',\n",
    "    'modeled_reporting_usage',\n",
    "    'modeled_savings',\n",
    "]].plot(ax=axes[0])\n",
    "axes[0].set_title('Total normalized/annualized savings')\n",
    "\n",
    "annualized_savings_billing[[\n",
    "    'modeled_baseline_cooling_load',\n",
    "    'modeled_reporting_cooling_load',\n",
    "    'modeled_cooling_load_savings',\n",
    "]].plot(ax=axes[1])\n",
    "axes[1].set_title('Modeled cooling load savings')\n",
    "\n",
    "annualized_savings_billing[[\n",
    "    'modeled_baseline_heating_load',\n",
    "    'modeled_reporting_heating_load',\n",
    "    'modeled_heating_load_savings',\n",
    "]].plot(ax=axes[2])\n",
    "axes[2].set_title('Modeled heating load savings')\n",
    "\n",
    "ax = annualized_savings_billing[[\n",
    "    'modeled_baseline_base_load',\n",
    "    'modeled_reporting_base_load',\n",
    "    'modeled_base_load_savings',\n",
    "]].plot(ax=axes[3])\n",
    "axes[3].set_title('Modeled base load savings')\n",
    "lim = axes[3].set_ylim((0, None))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, as totals, the annualized savings look pretty similar to the metered savings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_savings_hourly = annualized_savings_hourly.modeled_savings.sum()\n",
    "percent_savings_hourly = total_savings_hourly / annualized_savings_hourly.modeled_baseline_usage.sum() * 100\n",
    "print('Hourly: Saved {:.1f} kWh in first year ({:.1f}%)'.format(total_savings_hourly, percent_savings_hourly))\n",
    "\n",
    "total_savings_daily = annualized_savings_daily.modeled_savings.sum()\n",
    "percent_savings_daily = total_savings_daily / annualized_savings_daily.modeled_baseline_usage.sum() * 100\n",
    "print('Daily: Saved {:.1f} kWh in first year ({:.1f}%)'.format(total_savings_daily, percent_savings_daily))\n",
    "\n",
    "total_savings_billing = annualized_savings_billing.modeled_savings.sum()\n",
    "percent_savings_billing = total_savings_billing / annualized_savings_billing.modeled_baseline_usage.sum() * 100\n",
    "print('Billing: Saved {:.1f} kWh in first year ({:.1f}%)'.format(total_savings_billing, percent_savings_billing))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we're interested in seeing more about models the CalTRACK method tried, we can even plot all the model candidates as well. There are a ton of these, so the reduced alpha makes it a bit easier to see what's going on. Each faint line represents a model that was tried and bested by the (orange) selected model, which had the highest r-squared. Candidates appear green if `QUALIFIED` and red if `DISQUALIFIED`.  A model might be disqualified if it had unphysical (i.e., negative) coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = eemeter.plot_energy_signature(meter_data_daily, temperature_data_daily)\n",
    "baseline_model_results_daily.plot(\n",
    "    ax=ax,\n",
    "    candidate_alpha=0.02,\n",
    "    with_candidates=True,\n",
    "    temp_range=(-5, 88)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = eemeter.plot_energy_signature(meter_data_billing, temperature_data_billing)\n",
    "baseline_model_results_billing.plot(\n",
    "    ax=ax,\n",
    "    candidate_alpha=0.02,\n",
    "    with_candidates=True,\n",
    "    temp_range=(18, 80)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CalTRACK Hourly plots\n",
    "\n",
    "\n",
    "Coming soon."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running EEMeter Hourly and Daily in one go.\n",
    "\n",
    "If you want to run eemeter hourly/daily in one go, eemeter.caltrack_hourly and eemeter.caltrack_daily will do this for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gas_hourly, temperature_data_gas, metadata_gas_hourly = eemeter.load_sample('il-gas-hdd-only-hourly')\n",
    "electricity_hourly, temperature_data_electricity, metadata_electricity_hourly = eemeter.load_sample('il-electricity-cdd-hdd-hourly')\n",
    "\n",
    "gas_hourly, electricity_hourly, temperature_data_gas, temperature_data_electricity = eemeter.trim(\n",
    "    gas_hourly, electricity_hourly, temperature_data_gas, temperature_data_electricity\n",
    ")\n",
    "\n",
    "metered_savings_dataframe_hourly = eemeter.caltrack_hourly(\n",
    "    gas = gas_hourly,\n",
    "    elec = electricity_hourly,\n",
    "    temperature_data = temperature_data_gas,\n",
    "    blackout_start_date = gas_hourly.index.min() + relativedelta(years=1),\n",
    "    blackout_end_date = gas_hourly.index.min() + relativedelta(years=1)\n",
    ")\n",
    "\n",
    "metered_savings_dataframe_hourly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gas_daily, temperature_data_gas_daily, metadata_gas_daily = eemeter.load_sample('il-gas-hdd-only-daily')\n",
    "electricity_daily, temperature_data_electricity_daily, metadata_electricity_daily = eemeter.load_sample('il-electricity-cdd-hdd-daily')\n",
    "\n",
    "#trimming meter datasets. Note that frequency 'D' should be specified here.\n",
    "gas_daily, electricity_daily = eemeter.trim(\n",
    "    gas_daily, electricity_daily, freq='D'\n",
    ")\n",
    "\n",
    "metered_savings_dataframe_daily = eemeter.caltrack_daily(\n",
    "    gas = gas_daily,\n",
    "    elec = electricity_daily,\n",
    "    temperature_data = temperature_data_gas,\n",
    "    blackout_start_date = gas_daily.index.min() + relativedelta(years=1),\n",
    "    blackout_end_date = gas_daily.index.min() + relativedelta(years=1)\n",
    ")\n",
    "\n",
    "metered_savings_dataframe_daily"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspecting CalTRACKUsagePerDayModelResults objects: status, candidates, warnings, json\n",
    "\n",
    "\n",
    "In addition to being plottable, the model_fit object is an instance of the class [eemeter.ModelFit](http://eemeter.openee.io/api.html#eemeter.ModelFit) and contains a bunch of interesting information about this modeling process. \n",
    "\n",
    "For instance, there's a status. This status is one of the following:\n",
    "\n",
    "- `'SUCCESS'`: qualified model selected.\n",
    "- `'NO MODEL'`: no candidate models qualified.\n",
    "- `'NO DATA'`: no data was given."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_model_results_billing.status, baseline_model_results_daily.status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is also a \"best\" candidate model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_model_results_billing.model, baseline_model_results_daily.model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And a list of all candidate models that were tried, many of which have (much) lower r-squared than the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_model_results_billing.candidates[:5]  # (there are a lot, so only showing the first 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_model_results_daily.candidates[:5] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any associated warnings on both the model_fit object and the best candidate model object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_model_results_billing.warnings, baseline_model_results_billing.warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_model_results_daily.warnings, baseline_model_results_daily.warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best models don't appear to have any issues but the billing model did (see the faint red lines in the chart above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disqualified_candidates = [\n",
    "    candidate\n",
    "    for candidate in baseline_model_results_billing.candidates\n",
    "    if candidate.status == 'DISQUALIFIED'\n",
    "]  # this is a python list comprehension\n",
    "disqualified_candidates[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The warnings associated with the disqualified candidates will be a bit more interesting. For instance, this one was disqualified because the 'beta_hdd' parameter was negative, which is unphysicial behavior that the CalTRACK working group should be considered to be evidence of overfitting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json  # for nice indentation\n",
    "warning = disqualified_candidates[0].warnings[0]\n",
    "print(json.dumps(warning.json(), indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The whole model can be serialized. The `.json(with_candidates=True)` flag will also serialize all candidate models results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(json.dumps(baseline_model_results_billing.json(), indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(json.dumps(baseline_model_results_daily.json(), indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CalTRACK Data Sufficiency\n",
    "\n",
    "Another important part of the CalTRACK methods are the data sufficiency requirements. We can check the data sufficiency requirements of our baseline data. Note that we include the requested end dates to indicate the _intended_ extent of the period should stop at the baseline end date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_data_sufficiency_billing = eemeter.caltrack_sufficiency_criteria(\n",
    "    design_matrix_billing, requested_start=None, requested_end=baseline_end_date)\n",
    "\n",
    "baseline_data_sufficiency_daily = eemeter.caltrack_sufficiency_criteria(\n",
    "    design_matrix_daily, requested_start=None, requested_end=baseline_end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_data_sufficiency_billing.warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_data_sufficiency_daily.warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These warnings carry useful information about the extent of the data sufficiency issues:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(json.dumps(baseline_data_sufficiency_billing.json(), indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(json.dumps(baseline_data_sufficiency_daily.json(), indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next steps\n",
    "----------\n",
    "\n",
    "Congrats! You've finished the basic tutorial. The following are all highly recommended as ways to learn more about open energy efficiency metering:\n",
    "\n",
    " - Read the docs at http://eemeter.openee.io\n",
    " - Match sites or obtain weather data from public sources with [EEWeather](http://eeweather.openee.io)\n",
    " - Try out the eemeter on your own data. You might find these useful: [eemeter data loading methods](http://eemeter.openee.io/api.html#data-loading)\n",
    " - Try another sample.\n",
    "\n",
    "The following prints the names of the other samples to try out with this notebook, if interested:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eemeter.samples()"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
